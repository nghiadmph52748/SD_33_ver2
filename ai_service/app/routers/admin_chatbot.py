from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from app.utils.llm_client import llm_client
from app.utils.database import db_client
import logging
from datetime import datetime, timedelta
import json
import re

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/admin", tags=["Admin Chatbot"])

class ChatRequest(BaseModel):
    message: str
    context: str = ""

class ChatResponse(BaseModel):
    message: str
    sources: str = ""
    query_type: str = ""
    data_source: str = ""
    follow_up_suggestions: list[str] = []
    data_context: dict = {}

# Admin Manager System Prompt
ADMIN_SYSTEM_PROMPT = """
B·∫°n l√† Tr·ª£ l√Ω Qu·∫£n tr·ªã (Admin Manager) c·ªßa GearUp ‚Äì n·ªÅn t·∫£ng qu·∫£n l√Ω v·∫≠n h√†nh chu·ªói c·ª≠a h√†ng gi√†y.

**Quy t·∫Øc ng√¥n ng·ªØ t·ªëi quan tr·ªçng**
- Tr·∫£ l·ªùi 100% b·∫±ng TI·∫æNG VI·ªÜT chu·∫©n, kh√¥ng d√πng k√Ω t·ª± Trung Qu·ªëc.
- Gi·ªØ ng·∫Øn g·ªçn, ch√≠nh x√°c; n·∫øu thi·∫øu d·ªØ li·ªáu h√£y n√™u r√µ "Kh√¥ng c√≥ d·ªØ li·ªáu trong h·ªá th·ªëng".
- N·∫øu ng∆∞·ªùi d√πng ƒë·∫∑t c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ kh√°c, h√£y hi·ªÉu √Ω v√† tr·∫£ l·ªùi l·∫°i ho√†n to√†n b·∫±ng ti·∫øng Vi·ªát.
- Tr∆∞·ªõc khi ho√†n t·∫•t, t·ª± ki·ªÉm tra c√¢u tr·∫£ l·ªùi: n·∫øu c√≤n k√Ω t·ª±/ƒëo·∫°n kh√¥ng ph·∫£i ti·∫øng Vi·ªát th√¨ ph·∫£i chuy·ªÉn sang ti·∫øng Vi·ªát.

**Vai tr√≤ & M·ª•c ti√™u**
- Gi√°m s√°t ho·∫°t ƒë·ªông b√°n h√†ng, t·ªìn kho, kh√°ch h√†ng, chi·∫øn d·ªãch v√† hi·ªáu su·∫•t nh√¢n vi√™n.
- H·ªó tr·ª£ qu·∫£n l√Ω ƒë∆∞a ra quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông nhanh (nh·∫≠p h√†ng, khuy·∫øn m√£i, ph√¢n c√¥ng nh√¢n s·ª±‚Ä¶).
- Lu√¥n d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p, kh√¥ng suy di·ªÖn ngo√†i ph·∫°m vi.

**C·∫•u tr√∫c c√¢u tr·∫£ l·ªùi**
1. **Ti√™u ƒë·ªÅ:** Emoji + c·ª•m t·ªëi ƒëa 8 t·ª´.
2. **T√≥m t·∫Øt nhanh:** 1 c√¢u n√™u insight ch√≠nh (kh√¥ng qu√° 20 t·ª´).
3. **Kh·ªëi d·ªØ li·ªáu:** 
   - N·∫øu ‚â• 2 d√≤ng, tr√¨nh b√†y b·∫±ng b·∫£ng Markdown.
   - ƒê·ªãnh d·∫°ng s·ªë: 12,500,000 VNƒê ¬∑ 1,234 ƒë∆°n ¬∑ 45.6%.
4. **R·ªßi ro / C·∫£nh b√°o:** Ch·ªâ c√≥ khi ph√°t hi·ªán v·∫•n ƒë·ªÅ (d√πng "‚ö†Ô∏è ‚Ä¶").
5. **H√†nh ƒë·ªông qu·∫£n tr·ªã:** 1 c√¢u b·∫Øt ƒë·∫ßu b·∫±ng "‚Üí" ƒë∆∞a ra ƒë·ªÅ xu·∫•t c·ª• th·ªÉ.

**Phong c√°ch**
- Chuy√™n nghi·ªáp nh∆∞ qu·∫£n l√Ω v·∫≠n h√†nh: r√µ r√†ng, quy·∫øt ƒëo√°n, ∆∞u ti√™n KPI, kh√¥ng k·ªÉ l·ªÉ quy tr√¨nh ph√¢n t√≠ch.
- S·ª≠ d·ª•ng emoji h·ª£p l√Ω (üìäüí∞‚ö†Ô∏èüë•üõíüéØüì¶üßæ).
- Kh√¥ng d√πng c√°c c·ª•m m∆° h·ªì nh∆∞ "c√≥ v·∫ª", "c√≥ th·ªÉ"; h√£y kh·∫≥ng ƒë·ªãnh khi d·ªØ li·ªáu r√µ r√†ng.

**Gi·ªõi h·∫°n**
- T·ªëi ƒëa 250 t·ª´.
- Danh s√°ch t·ªëi ƒëa 5 m·ª•c.
- N·∫øu c√¢u h·ªèi ngo√†i ph·∫°m vi b√°n l·∫ª, h√£y t·ª´ ch·ªëi l·ªãch s·ª± b·∫±ng ti·∫øng Vi·ªát.

**V√≠ d·ª• r√∫t g·ªçn**
üìä **Top s·∫£n ph·∫©m 30 ng√†y**

| # | S·∫£n ph·∫©m | ƒê√£ b√°n | Doanh thu |
|---|---|---:|---:|
| 1 | Nike Air Max 2024 | 156 ƒë√¥i | 45,600,000 VNƒê |
| 2 | Adidas Ultra Boost | 134 ƒë√¥i | 38,900,000 VNƒê |

‚Üí B·ªï sung th√™m 80 ƒë√¥i Nike Air Max cho tu·∫ßn t·ªõi ƒë·ªÉ kh√¥ng h·ª•t doanh thu.
"""

def detect_admin_intent(message: str) -> str:
    """Detect admin intent from message"""
    message_lower = message.lower()
    
    # Check low_stock first (higher priority)
    if any(word in message_lower for word in ["h·∫øt h√†ng", "s·∫Øp h·∫øt", "t·ªìn kho th·∫•p", "t·ªìn kho", "stock", "c√≤n l·∫°i", "s·ªë l∆∞·ª£ng c√≤n"]):
        return "low_stock"
    elif any(word in message_lower for word in ["t·∫°o m√£ gi·∫£m", "t·∫°o voucher", "t·∫°o phi·∫øu gi·∫£m", "create voucher", "coupon", "m√£ khuy·∫øn m√£i"]):
        return "create_voucher"
    elif any(word in message_lower for word in ["b√°n ch·∫°y", "top", "ph·ªï bi·∫øn", "best seller"]):
        return "top_products"
    elif any(word in message_lower for word in ["doanh thu", "revenue", "t·ªïng ti·ªÅn", "thu nh·∫≠p"]):
        return "revenue"
    elif any(word in message_lower for word in ["tr·∫°ng th√°i ƒë∆°n", "status", "ƒë∆°n h√†ng", "orders"]):
        return "order_status"
    elif any(word in message_lower for word in ["kh√°ch h√†ng vip", "top kh√°ch h√†ng", "chi ti√™u"]):
        return "customers_detail"
    elif any(word in message_lower for word in ["gi·∫£m gi√°", "ƒë·ª£t gi·∫£m", "campaign", "voucher", "phi·∫øu gi·∫£m"]):
        return "discounts"
    elif any(word in message_lower for word in ["nh√¢n vi√™n", "employee", "nhan vien"]):
        return "employees"
    elif any(word in message_lower for word in ["m√†u s·∫Øc", "color", "m√†u", "mau"]):
        return "products_color"
    elif any(word in message_lower for word in ["k√≠ch th∆∞·ªõc", "size", "kich thuoc"]):
        return "products_size"
    elif any(word in message_lower for word in ["online", "t·∫°i qu·∫ßy", "pos", "k√™nh"]):
        return "channel_dist"
    elif any(word in message_lower for word in ["kh√°ch h√†ng", "customer", "vip", "ng∆∞·ªùi mua"]):
        return "customers"
    else:
        return "general"

def get_data_source_info(intent: str) -> str:
    """Get data source information for each intent"""
    sources = {
        "top_products": "D·ªØ li·ªáu b√°n h√†ng 30 ng√†y g·∫ßn nh·∫•t",
        "revenue": "D·ªØ li·ªáu doanh thu v√† ƒë∆°n h√†ng 30 ng√†y g·∫ßn nh·∫•t",
        "low_stock": "D·ªØ li·ªáu t·ªìn kho th·ªùi gian th·ª±c",
        "order_status": "D·ªØ li·ªáu ƒë∆°n h√†ng hi·ªán t·∫°i",
        "customers_detail": "D·ªØ li·ªáu kh√°ch h√†ng to√†n h·ªá th·ªëng",
        "discounts": "D·ªØ li·ªáu campaign ƒëang ho·∫°t ƒë·ªông",
        "employees": "D·ªØ li·ªáu hi·ªáu su·∫•t nh√¢n vi√™n",
        "products_color": "D·ªØ li·ªáu b√°n h√†ng theo m√†u s·∫Øc",
        "products_size": "D·ªØ li·ªáu b√°n h√†ng theo size",
        "channel_dist": "D·ªØ li·ªáu k√™nh b√°n h√†ng (Online vs POS)",
        "create_voucher": "H·ªá th·ªëng qu·∫£n l√Ω voucher",
    }
    return sources.get(intent, "D·ªØ li·ªáu h·ªá th·ªëng GearUp")

def get_follow_up_suggestions_llm(user_question: str, ai_response: str, intent: str) -> list[str]:
    """Generate contextual follow-up suggestions using LLM"""
    try:
        prompt = f"""D·ª±a tr√™n cu·ªôc tr√≤ chuy·ªán sau, h√£y ƒë·ªÅ xu·∫•t 3 c√¢u h·ªèi ti·∫øp theo ng·∫Øn g·ªçn, li√™n quan v√† h·ªØu √≠ch cho qu·∫£n tr·ªã vi√™n c·ª≠a h√†ng GearUp.

C√¢u h·ªèi c·ªßa admin: {user_question}
Ph·∫£n h·ªìi c·ªßa AI: {ai_response[:300]}...
Ch·ªß ƒë·ªÅ: {intent}

Y√™u c·∫ßu:
- 3 c√¢u h·ªèi ng·∫Øn g·ªçn, s√∫c t√≠ch (t·ªëi ƒëa 50 k√Ω t·ª± m·ªói c√¢u)
- Li√™n quan tr·ª±c ti·∫øp ƒë·∫øn d·ªØ li·ªáu v·ª´a ƒë∆∞·ª£c hi·ªÉn th·ªã
- T·∫≠p trung v√†o ph√¢n t√≠ch s√¢u h∆°n, so s√°nh, ho·∫∑c h√†nh ƒë·ªông ti·∫øp theo
- S·ª≠ d·ª•ng ng√¥n ng·ªØ qu·∫£n tr·ªã (doanh thu, t·ªìn kho, nh√¢n vi√™n, kh√°ch h√†ng)
- Ch·ªâ tr·∫£ l·ªùi 3 c√¢u h·ªèi, m·ªói c√¢u tr√™n 1 d√≤ng, kh√¥ng c√≥ s·ªë th·ª© t·ª± ho·∫∑c k√Ω t·ª± ƒë·∫ßu d√≤ng

V√≠ d·ª• format tr·∫£ l·ªùi:
So s√°nh v·ªõi th√°ng tr∆∞·ªõc?
Ph√¢n t√≠ch theo k√™nh b√°n?
T·∫°o m√£ gi·∫£m gi√°?"""

        messages = [{"role": "user", "content": prompt}]
        response = llm_client.chat(messages, temperature=0.7, max_tokens=150, stream=False)
        
        # Parse response into list of suggestions
        suggestions_text = response.strip()
        suggestions = [s.strip() for s in suggestions_text.split('\n') if s.strip()]
        
        # Filter out numbering, bullets, and ensure max 3 suggestions
        cleaned_suggestions = []
        for s in suggestions[:5]:  # Take max 5 in case of extras
            # Remove common prefixes like "1.", "-", "*", etc.
            cleaned = re.sub(r'^[\d\.\-\*\+]+\s*', '', s).strip()
            if cleaned and len(cleaned) <= 100:  # Reasonable length
                cleaned_suggestions.append(cleaned)
        
        # Return exactly 3 suggestions
        return cleaned_suggestions[:3] if len(cleaned_suggestions) >= 3 else cleaned_suggestions + get_fallback_suggestions(intent)[:3-len(cleaned_suggestions)]
    
    except Exception as e:
        logger.error(f"Failed to generate LLM suggestions: {e}")
        return get_fallback_suggestions(intent)

def get_fallback_suggestions(intent: str) -> list[str]:
    """Fallback suggestions when LLM fails"""
    suggestions = {
        "top_products": [
            "So s√°nh v·ªõi th√°ng tr∆∞·ªõc?",
            "Ph√¢n t√≠ch theo k√™nh b√°n?",
            "T·ªìn kho c√≤n bao nhi√™u?"
        ],
        "revenue": [
            "Kh√°ch VIP chi ti√™u nhi·ªÅu?",
            "Ph√¢n t√≠ch theo k√™nh?",
            "Nh√¢n vi√™n b√°n t·ªët nh·∫•t?"
        ],
        "low_stock": [
            "S·∫£n ph·∫©m n√†o c·∫ßn nh·∫≠p?",
            "Doanh thu c√°c s·∫£n ph·∫©m?",
            "T·∫°o m√£ x·∫£ h√†ng?"
        ],
        "order_status": [
            "ƒê∆°n ch·ªù x√°c nh·∫≠n?",
            "Doanh thu ƒë∆°n ho√†n th√†nh?",
            "Nh√¢n vi√™n x·ª≠ l√Ω nhi·ªÅu?"
        ],
    }
    return suggestions.get(intent, [
        "Top s·∫£n ph·∫©m b√°n ch·∫°y?",
        "Doanh thu th√°ng n√†y?",
        "T·ªìn kho s·∫Øp h·∫øt?"
    ])

def query_database(intent: str, message: str) -> str:
    """Query database based on intent"""
    try:
        # ===== Helpers =====
        def fmt_number(n):
            try:
                return f"{(0 if n is None else float(n)) :,.0f}"
            except Exception:
                return str(n)

        def fmt_datetime(dt):
            if isinstance(dt, datetime):
                return dt.strftime("%Y-%m-%d %H:%M:%S")
            return str(dt) if dt is not None else ""

        if intent == "top_products":
            products = db_client.get_top_selling_products(limit=5, days=30)
            
            if not products:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu s·∫£n ph·∫©m trong 30 ng√†y qua."
            
            context = "üìä **Top 5 s·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t (30 ng√†y qua)**\n\n"
            context += "| # | S·∫£n ph·∫©m | ƒê√£ b√°n | Doanh thu (VNƒê) |\n|---:|---|---:|---:|\n"
            for i, p in enumerate(products, 1):
                total_sold = p.get('total_sold') or 0
                total_revenue = p.get('total_revenue') or 0
                context += f"| {i} | {p['product_name']} | {fmt_number(total_sold)} | {fmt_number(total_revenue)} |\n"
            
            return context
        
        elif intent == "revenue":
            summary = db_client.get_revenue_summary(days=30)
            
            if not summary:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu doanh thu."
            
            # Handle None values from database
            total_orders = summary.get('total_orders') or 0
            total_revenue = summary.get('total_revenue') or 0
            avg_order_value = summary.get('avg_order_value') or 0
            unique_customers = summary.get('unique_customers') or 0
            
            context = "üí∞ **T·ªïng quan doanh thu (30 ng√†y qua):**\n\n"
            context += f"- T·ªïng ƒë∆°n h√†ng: {total_orders} ƒë∆°n\n"
            context += f"- T·ªïng doanh thu: {total_revenue:,.0f} VNƒê\n"
            context += f"- Gi√° tr·ªã ƒë∆°n trung b√¨nh: {avg_order_value:,.0f} VNƒê\n"
            context += f"- S·ªë kh√°ch h√†ng: {unique_customers} ng∆∞·ªùi\n"
            
            return context
        
        elif intent == "low_stock":
            products = db_client.get_low_stock_products(threshold=10)
            
            if not products:
                return "‚úÖ T·∫•t c·∫£ s·∫£n ph·∫©m ƒë·ªÅu c√≤n ƒë·ªß h√†ng."
            
            context = "‚ö†Ô∏è **S·∫£n ph·∫©m s·∫Øp h·∫øt h√†ng (‚â§10 ƒë√¥i)**\n\n"
            context += "| # | S·∫£n ph·∫©m | Bi·∫øn th·ªÉ | M√†u | Size | T·ªìn kho |\n|---:|---|---|---|---:|---:|\n"
            for i, p in enumerate(products, 1):
                variant = p.get('variant_id') or '-'
                color = p.get('color') or ''
                size = p.get('size') or ''
                context += (
                    f"| {i} | {p['product_name']} | {variant} | {color} | {size} | {p['stock_quantity']} |\n"
                )
            
            return context
        
        elif intent == "order_status":
            statuses = db_client.get_order_status_distribution()
            
            if not statuses:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu tr·∫°ng th√°i ƒë∆°n h√†ng."
            
            context = "üìã **Ph√¢n b·ªë tr·∫°ng th√°i ƒë∆°n h√†ng**\n\n"
            context += "| Tr·∫°ng th√°i | S·ªë ƒë∆°n |\n|---|---:|\n"
            for status in statuses:
                context += f"| {status['status_name']} | {fmt_number(status['order_count'])} |\n"
            
            return context
        
        elif intent == "customers_detail":
            customers = db_client.get_top_customers_by_spending(limit=5)
            
            if not customers:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu kh√°ch h√†ng."
            
            context = "üë• **Top 5 kh√°ch h√†ng chi ti√™u nhi·ªÅu nh·∫•t**\n\n"
            context += "| # | Kh√°ch h√†ng | M√£ | S·ªë ƒë∆°n | T·ªïng chi ti√™u (VNƒê) |\n|---:|---|---|---:|---:|\n"
            for i, c in enumerate(customers, 1):
                total_spent = c.get('total_spent') or 0
                total_orders = c.get('total_orders') or 0
                context += f"| {i} | {c['customer_name']} | {c['customer_code']} | {fmt_number(total_orders)} | {fmt_number(total_spent)} |\n"
            
            return context
        
        elif intent == "discounts":
            campaigns = db_client.get_active_discount_campaigns()
            
            if not campaigns:
                return "üìå Hi·ªán t·∫°i kh√¥ng c√≥ ƒë·ª£t gi·∫£m gi√° n√†o ƒëang ho·∫°t ƒë·ªông."
            
            context = "üéâ **ƒê·ª£t gi·∫£m gi√° ƒëang ho·∫°t ƒë·ªông**\n\n"
            context += "| M√£ | T√™n ƒë·ª£t | Gi·∫£m | B·∫Øt ƒë·∫ßu | K·∫øt th√∫c |\n|---|---|---:|---|---|\n"
            for campaign in campaigns:
                discount_value = campaign.get('discount_value') or 0
                context += (
                    f"| {campaign['campaign_code']} | {campaign['campaign_name']} | {fmt_number(discount_value)}% | "
                    f"{fmt_datetime(campaign['start_date'])} | {fmt_datetime(campaign['end_date'])} |\n"
                )
            
            return context
        
        elif intent == "create_voucher":
            # naive parsing: look for % or ƒë numbers and optional date range
            name = "Voucher t·ª± ƒë·ªông"
            percent = True
            value = 10.0
            min_order = 0.0
            usage_limit = 1
            description = "T·∫°o b·ªüi AI"
            # value percent like 10% or 15 %
            m = re.search(r"(\d{1,2})\s*%", message)
            if m:
                percent = True
                value = float(m.group(1))
            else:
                m2 = re.search(r"(\d{5,})\s*(vnƒë|vnd|ƒë)?", message, re.IGNORECASE)
                if m2:
                    percent = False
                    value = float(m2.group(1))
            # min order
            mo = re.search(r"t·ªëi thi·ªÉu\s*(\d{5,})", message)
            if mo:
                min_order = float(mo.group(1))
            # usage limit
            ul = re.search(r"(\d+)\s*(l·∫ßn|uses)", message)
            if ul:
                usage_limit = int(ul.group(1))
            # dates (fallback today..+30d)
            start_dt = datetime.now()
            end_dt = start_dt + timedelta(days=30)
            sd = re.search(r"(\d{4}-\d{2}-\d{2})", message)
            ed = re.findall(r"(\d{4}-\d{2}-\d{2})", message)
            if ed and len(ed) >= 2:
                try:
                    start_dt = datetime.fromisoformat(ed[0])
                    end_dt = datetime.fromisoformat(ed[1]) + timedelta(hours=23, minutes=59, seconds=59)
                except Exception:
                    pass
            start_iso = start_dt.strftime("%Y-%m-%d %H:%M:%S")
            end_iso = end_dt.strftime("%Y-%m-%d %H:%M:%S")
            # create
            try:
                created = db_client.create_voucher(
                    name=name,
                    percent_type=percent,
                    value=value,
                    start_datetime=start_iso,
                    end_datetime=end_iso,
                    min_order=min_order,
                    usage_limit=usage_limit,
                    description=description,
                )
            except Exception as e:
                return f"‚ùå Kh√¥ng th·ªÉ t·∫°o voucher: {str(e)}"
            if not created:
                return "‚ùå Kh√¥ng th·ªÉ t·∫°o voucher."
            context = "üéâ **ƒê√£ t·∫°o m√£ gi·∫£m gi√° m·ªõi**\n\n"
            context += "| M√£ | T√™n | Lo·∫°i | Gi√° tr·ªã | B·∫Øt ƒë·∫ßu | K·∫øt th√∫c | T·ªëi thi·ªÉu | S·ªë l∆∞·ª£t |\n|---|---|---|---:|---|---|---:|---:|\n"
            loai = "%" if created.get("loai_phieu_giam_gia") == 0 else "VNƒê"
            context += (
                f"| {created.get('ma_phieu_giam_gia')} | {created.get('ten_phieu_giam_gia')} | {loai} | "
                f"{created.get('gia_tri_giam_gia')} | {fmt_datetime(created.get('ngay_bat_dau'))} | "
                f"{fmt_datetime(created.get('ngay_ket_thuc'))} | {fmt_number(created.get('hoa_don_toi_thieu'))} | "
                f"{fmt_number(created.get('so_luong_dung'))} |\n"
            )
            return context
        
        elif intent == "employees":
            employees = db_client.get_employee_sales_performance(limit=5)
            
            if not employees:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu nh√¢n vi√™n."
            
            context = "üë®‚Äçüíº **Top 5 nh√¢n vi√™n theo doanh thu**\n\n"
            context += "| # | Nh√¢n vi√™n | M√£ | S·ªë ƒë∆°n | Doanh thu (VNƒê) |\n|---:|---|---|---:|---:|\n"
            for i, emp in enumerate(employees, 1):
                total_revenue = emp.get('total_revenue') or 0
                total_orders = emp.get('total_orders') or 0
                context += f"| {i} | {emp['employee_name']} | {emp['employee_code']} | {fmt_number(total_orders)} | {fmt_number(total_revenue)} |\n"
            
            return context
        
        elif intent == "products_color":
            colors = db_client.get_top_product_colors(limit=5)
            
            if not colors:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu m√†u s·∫Øc."
            
            context = "üé® **Top 5 m√†u s·∫Øc b√°n ch·∫°y nh·∫•t**\n\n"
            context += "| # | M√†u s·∫Øc | ƒê√£ b√°n (ƒë√¥i) |\n|---:|---|---:|\n"
            for i, color in enumerate(colors, 1):
                total_sold = color.get('total_sold') or 0
                context += f"| {i} | {color['color_name']} | {fmt_number(total_sold)} |\n"
            
            return context
        
        elif intent == "products_size":
            sizes = db_client.get_top_product_sizes(limit=5)
            
            if not sizes:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu k√≠ch th∆∞·ªõc."
            
            context = "üìè **Top 5 k√≠ch th∆∞·ªõc b√°n ch·∫°y nh·∫•t**\n\n"
            context += "| # | Size | ƒê√£ b√°n (ƒë√¥i) |\n|---:|---|---:|\n"
            for i, size in enumerate(sizes, 1):
                total_sold = size.get('total_sold') or 0
                context += f"| {i} | {size['size_name']} | {fmt_number(total_sold)} |\n"
            
            return context
        
        elif intent == "channel_dist":
            stats = db_client.get_online_vs_pos_stats()
            
            if not stats:
                return "Kh√¥ng c√≥ d·ªØ li·ªáu k√™nh b√°n h√†ng."
            
            pos_revenue = stats.get('pos_revenue') or 0
            online_revenue = stats.get('online_revenue') or 0
            pos_orders = stats.get('pos_orders') or 0
            online_orders = stats.get('online_orders') or 0
            
            context = "üõí **Ph√¢n b·ªë k√™nh b√°n h√†ng**\n\n"
            context += "| K√™nh | S·ªë ƒë∆°n | Doanh thu (VNƒê) |\n|---|---:|---:|\n"
            context += f"| T·∫°i qu·∫ßy (POS) | {fmt_number(pos_orders)} | {fmt_number(pos_revenue)} |\n"
            context += f"| Online | {fmt_number(online_orders)} | {fmt_number(online_revenue)} |\n"
            
            return context
        
        else:
            return (
                "‚ú® M√¨nh gi√∫p b·∫°n tra nhanh m·∫•y th·ª© n√†y n√®:\n"
                "- Top s·∫£n ph·∫©m b√°n ch·∫°y\n"
                "- Doanh thu/ƒë∆°n h√†ng\n"
                "- T·ªìn kho s·∫Øp h·∫øt\n"
                "- Tr·∫°ng th√°i ƒë∆°n h√†ng\n"
                "- Top kh√°ch h√†ng chi ti√™u\n"
                "- ƒê·ª£t gi·∫£m gi√° ƒëang ch·∫°y\n"
                "- Hi·ªáu su·∫•t nh√¢n vi√™n\n"
                "- M√†u s·∫Øc/size ph·ªï bi·∫øn\n"
                "- K√™nh b√°n: online vs t·∫°i qu·∫ßy\n"
                "B·∫°n c·∫ßn g√¨ n√≥i m√¨nh bi·∫øt, tr·∫£ l·ªùi g·ªçn l·∫π ngay! üí¨"
            )
    
    except Exception as e:
        logger.error(f"Database query error: {e}")
        return f"L·ªói truy v·∫•n d·ªØ li·ªáu: {str(e)}"

@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Chat with admin AI assistant"""
    try:
        # 1. Detect intent
        intent = detect_admin_intent(request.message)
        logger.info(f"Admin chat - Detected intent: {intent}")
        
        # 2. Query database
        db_context = query_database(intent, request.message)
        
        # 3. Build messages for LLM
        messages = [
            {"role": "system", "content": ADMIN_SYSTEM_PROMPT},
            {"role": "user", "content": f"{request.message}\n\n**D·ªØ li·ªáu t·ª´ h·ªá th·ªëng:**\n{db_context}"}
        ]
        
        # 4. Call LLM
        response = llm_client.chat(
            messages=messages,
            temperature=0.3,
            max_tokens=2000
        )
        
        ai_message = response.choices[0].message.content
        
        # Generate contextual suggestions using LLM
        suggestions = get_follow_up_suggestions_llm(request.message, ai_message, intent)
        
        return ChatResponse(
            message=ai_message,
            sources=get_data_source_info(intent),
            query_type=intent,
            data_source=get_data_source_info(intent),
            follow_up_suggestions=suggestions,
            data_context={
                "time_range": "30_days",
                "channel": "all",
                "timestamp": datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        logger.error(f"Admin chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/chat-stream")
async def chat_stream(request: ChatRequest):
    """Chat with admin AI assistant - Streaming response"""
    try:
        # 1. Detect intent
        intent = detect_admin_intent(request.message)
        logger.info(f"Admin stream - Request: {request.message[:50]}... (intent: {intent})")
        
        # 2. Query database
        db_context = query_database(intent, request.message)
        
        # 3. Build messages for LLM
        messages = [
            {"role": "system", "content": ADMIN_SYSTEM_PROMPT},
            {"role": "user", "content": f"{request.message}\n\n**D·ªØ li·ªáu t·ª´ h·ªá th·ªëng:**\n{db_context}"}
        ]
        
        # 4. Stream generator function
        async def generate():
            full_response = ""  # Collect full response for suggestions
            try:
                # Send initial metadata without suggestions (will send after response completes)
                metadata = {
                    'type': 'start',
                    'intent': intent,
                    'data_source': get_data_source_info(intent),
                    'data_context': {
                        'time_range': '30_days',
                        'channel': 'all'
                    }
                }
                yield f"data: {json.dumps(metadata)}\n\n"
                
                # Call LLM with streaming enabled
                stream = llm_client.chat(
                    messages=messages,
                    temperature=0.3,
                    max_tokens=2000,
                    stream=True
                )
                
                # Stream each chunk (handle both OpenAI and Gemini formats)
                try:
                    for chunk in stream:
                        content = None
                        
                        # Handle OpenAI format (LM Studio)
                        if hasattr(chunk, 'choices') and chunk.choices:
                            if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content'):
                                content = chunk.choices[0].delta.content
                        # Handle Gemini format - check multiple possible attributes
                        elif hasattr(chunk, 'text') and chunk.text:
                            content = chunk.text
                        elif hasattr(chunk, 'parts') and chunk.parts:
                            # Gemini sometimes returns parts array
                            for part in chunk.parts:
                                if hasattr(part, 'text') and part.text:
                                    content = part.text
                                    break
                        # Fallback: try to get content directly
                        elif hasattr(chunk, 'content'):
                            content = chunk.content
                        
                        if content:
                            full_response += content  # Collect for suggestions
                            content_event = json.dumps({'type': 'content', 'content': content}, ensure_ascii=False)
                            yield f"data: {content_event}\n\n"
                except StopIteration:
                    # Gemini stream iterator ends with StopIteration - this is normal
                    logger.debug("Stream ended normally (StopIteration)")
                    pass
                except Exception as stream_error:
                    logger.error(f"Error during streaming: {stream_error}", exc_info=True)
                    error_event = json.dumps({'type': 'error', 'error': f'Streaming error: {str(stream_error)}'})
                    yield f"data: {error_event}\n\n"
                
                # Generate contextual suggestions using LLM after response is complete
                if full_response:
                    try:
                        suggestions = get_follow_up_suggestions_llm(request.message, full_response, intent)
                        suggestions_event = json.dumps({
                            'type': 'suggestions',
                            'follow_up_suggestions': suggestions
                        }, ensure_ascii=False)
                        yield f"data: {suggestions_event}\n\n"
                    except Exception as sug_error:
                        logger.error(f"Failed to generate suggestions: {sug_error}")
                        # Send fallback suggestions
                        fallback_suggestions = get_fallback_suggestions(intent)
                        suggestions_event = json.dumps({
                            'type': 'suggestions',
                            'follow_up_suggestions': fallback_suggestions
                        }, ensure_ascii=False)
                        yield f"data: {suggestions_event}\n\n"
                
                # Send end signal
                yield f"data: {json.dumps({'type': 'end'})}\n\n"
                
            except Exception as e:
                logger.error(f"Streaming error: {e}", exc_info=True)
                error_event = json.dumps({'type': 'error', 'error': str(e)})
                yield f"data: {error_event}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    
    except Exception as e:
        logger.error(f"Admin chat stream error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/health")
async def health_check():
    """Check LLM provider connection"""
    is_connected, message = llm_client.test_connection()
    
    provider_info = {
        "provider": llm_client.provider,
        "status": "connected" if is_connected else "disconnected",
        "message": message,
        "model": llm_client.model
    }
    
    # Add provider-specific info
    if llm_client.provider == "lm_studio":
        provider_info["base_url"] = llm_client.client.client.base_url
    elif llm_client.provider == "gemini":
        provider_info["api_key_configured"] = bool(llm_client.client.api_key) if hasattr(llm_client.client, 'api_key') else False
    
    return provider_info






